<!DOCTYPE html>
<html data-bs-theme="light" lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>SaPHaRI Lab - Research</title>
    <meta name="description" content="Currently research projects at the Social and Physical Human and Robot Interaction Lab at Case Western Reserve University. Our research involves robotics and computing, notably HRI and HCI.">
    <link rel="icon" type="image/jpeg" sizes="500x500" href="assets/img/logos/HumanRobotPink.jpg">
    <link rel="icon" type="image/jpeg" sizes="500x500" href="assets/img/logos/HumanRobotPink.jpg" media="(prefers-color-scheme: dark)">
    <link rel="icon" type="image/jpeg" sizes="500x500" href="assets/img/logos/HumanRobotPink.jpg">
    <link rel="icon" type="image/jpeg" sizes="500x500" href="assets/img/logos/HumanRobotPink.jpg" media="(prefers-color-scheme: dark)">
    <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="assets/css/Inter.css">
    <link rel="stylesheet" href="assets/css/bs-theme-overrides.css">
    <link rel="stylesheet" href="assets/css/aos.min.css">
    <link rel="stylesheet" href="assets/css/animate.min.css">
</head>

<body>
    <!-- Start: Navbar Centered Links -->
    <nav class="navbar navbar-expand-md sticky-top navbar-shrink" id="mainNav">
        <div class="container"><button data-bs-toggle="collapse" class="navbar-toggler" data-bs-target="#navcol-1"><span class="visually-hidden">Toggle navigation</span><span class="navbar-toggler-icon"></span></button>
            <div></div>
            <div class="collapse navbar-collapse d-flex flex-row justify-content-between" id="navcol-1"><a class="navbar-brand d-flex align-items-center" href="/">
                    <div class="d-flex"><span class="bs-icon-sm bs-icon-circle bs-icon-primary shadow d-flex justify-content-center align-items-center me-2 bs-icon"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 16 16" class="bi bi-robot">
                                <path d="M6 12.5a.5.5 0 0 1 .5-.5h3a.5.5 0 0 1 0 1h-3a.5.5 0 0 1-.5-.5M3 8.062C3 6.76 4.235 5.765 5.53 5.886a26.58 26.58 0 0 0 4.94 0C11.765 5.765 13 6.76 13 8.062v1.157a.933.933 0 0 1-.765.935c-.845.147-2.34.346-4.235.346-1.895 0-3.39-.2-4.235-.346A.933.933 0 0 1 3 9.219zm4.542-.827a.25.25 0 0 0-.217.068l-.92.9a24.767 24.767 0 0 1-1.871-.183.25.25 0 0 0-.068.495c.55.076 1.232.149 2.02.193a.25.25 0 0 0 .189-.071l.754-.736.847 1.71a.25.25 0 0 0 .404.062l.932-.97a25.286 25.286 0 0 0 1.922-.188.25.25 0 0 0-.068-.495c-.538.074-1.207.145-1.98.189a.25.25 0 0 0-.166.076l-.754.785-.842-1.7a.25.25 0 0 0-.182-.135Z"></path>
                                <path d="M8.5 1.866a1 1 0 1 0-1 0V3h-2A4.5 4.5 0 0 0 1 7.5V8a1 1 0 0 0-1 1v2a1 1 0 0 0 1 1v1a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2v-1a1 1 0 0 0 1-1V9a1 1 0 0 0-1-1v-.5A4.5 4.5 0 0 0 10.5 3h-2zM14 7.5V13a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V7.5A3.5 3.5 0 0 1 5.5 4h5A3.5 3.5 0 0 1 14 7.5"></path>
                            </svg></span><span><span style="font-weight: normal !important;">SaPHaRI Lab</span></span></div>
                </a>
                <div>
                    <ul class="navbar-nav mx-auto">
                        <li class="nav-item"></li>
                        <li class="nav-item"><a class="nav-link" href="/team.html">Team</a></li>
                        <li class="nav-item"><a class="nav-link active" href="/research.html">Research</a></li>
                        <li class="nav-item"><a class="nav-link" href="/equipment.html">Equipment</a></li>
                        <li class="nav-item"><a class="nav-link" href="/publications.html">Publications</a></li>
                        <li class="nav-item"><a class="nav-link" href="https://www.youtube.com/watch?v=xvFZjo5PgG0" target="_blank">News</a></li>
                    </ul>
                </div><a href="/contacts.html" style="padding-left: 10%;">Contact</a>
            </div>
        </div>
    </nav><!-- End: Navbar Centered Links -->
    <!-- Start: small header -->
    <header class="bg-primary-gradient">
        <!-- Start: Hero Clean Reverse -->
        <div class="container text-center d-flex d-sm-flex justify-content-center justify-content-sm-center pulse animated pt-4 pt-xl-5" style="padding-bottom: 40px;">
            <div class="col-6"><a href="/"><img class="img-fluid" src="assets/img/logos/Saphari%20Lab%20Logo%20Pink.png" width="100%"></a></div>
        </div><!-- End: Hero Clean Reverse -->
    </header><!-- End: small header -->
    <section class="py-5">
        <!-- Start: Projects Grid -->
        <div class="container py-5">
            <h2 class="fw-bold text-center" style="padding-bottom: 35px;"><span style="font-weight: normal !important;">Research Projects</span></h2>
            <div class="row row-cols-1 row-cols-md-2 mx-auto" style="max-width: 900px;">
                <div class="col mb-4" data-aos="fade-left" data-aos-once="true"><a href="#"><img class="rounded img-fluid shadow w-100 fit-cover" src="assets/img/research-projects/Media.png" style="height: 350px;"></a>
                    <div class="py-4">
                        <h4 class="fw-bold text-center"><span style="font-weight: normal !important;">AstroPsych</span></h4>
                        <p class="text-muted"><span style="color: rgb(51, 51, 51);">AstroPsych is a multimodal framework designed to provide dynamic mental health support in challenging environments where traditional support is limited or impossible. Leveraging asynchronous therapist guidance and real-time physiological signals to administer on-demand support sessions, AstroPsych adapts continuously to the evolving needs of individuals in crisis. AstroPsych offers a range of interaction methods, including text, voice, avatar, and robotic interfaces, to effectively meet diverse user preferences.</span></p>
                    </div>
                </div>
                <div class="col mb-4" data-aos="fade-right" data-aos-once="true"><a href="#"><img class="rounded img-fluid shadow w-100 fit-cover" src="assets/img/research-projects/GreetingsProject.jpg" style="height: 350px;"></a>
                    <div class="py-4">
                        <h4 class="fw-bold text-center"><span style="font-weight: normal !important;">RoboSOAR</span></h4>
                        <p class="text-muted"><span style="color: rgb(51, 51, 51);">First impressions significantly influence human relationships - can the same be said for robots? As robots become more integrated into our daily lives, this project explores how a robot’s initial greeting shapes human willingness to engage with it.RoboSOAR develops natural-looking gestures and behaviors.</span><br><br><span style="color: rgb(51, 51, 51);">This multi-stage machine learning model effectively learns and refines human-like gestures from large datasets, making them compatible with robots. Our testbed is a Baxter Robot (Rethink Robotics, 2011) mounted on a custom mobile base to study the impact of gestures, verbal greetings, and proxemic distance on human-robot interaction. This work integrates with the Compliant Gripper Project, improving tactile interactions for a more natural and comfortable social touch.</span></p>
                    </div>
                </div>
                <div class="col mb-4" data-aos="fade-left" data-aos-once="true"><a href="#"><img class="rounded img-fluid shadow w-100 fit-cover" src="assets/img/team/Noah_Medrano240.jpg" style="height: 350px;"></a>
                    <div class="py-4">
                        <h4 class="fw-bold text-center"><span style="font-weight: normal !important;">Affect-Sensing Wearables</span></h4>
                        <p class="text-muted"><span style="color: rgb(51, 51, 51);">This project focuses on developing affective computing technologies that address challenges in emotional regulation and promote social interaction for individuals with Autism Spectrum Disorder (ASD) and Post-Traumatic Stress Disorder (PTSD). People with these conditions often experience difficulty interpreting and expressing emotions (alexithymia), limiting their ability to engage in social interactions. The system aims to continuously monitor and quantify the user’s emotional state using a wearable device with non-invasive physiological sensors. Through a multi-modal actuation framework, the wearable will intuitively signal the wearer’s emotional state and/or social interaction desires, encouraging nearby humans to engage the wearer. This project explores real-time emotion sensing, modular actuation methods, and the broader impact of technology-mediated social touch in improving emotional well-being.</span></p>
                    </div>
                </div>
                <div class="col mb-4" data-aos="fade-right" data-aos-once="true"><a href="#"><img class="rounded img-fluid shadow w-100 fit-cover" src="assets/img/research-projects/CompliantGripper.png" style="height: 350px;"></a>
                    <div class="py-4">
                        <h4 class="fw-bold text-center"><span style="font-weight: normal !important;">Compliant Gripper</span></h4>
                        <p class="text-muted">a compliant robotic gripper optimized for social-physical human-robot interaction, incorporating fabric-mediated tactile sensing to enhance comfort and natural touch. While existing robotic grippers focus on dexterous manipulation, our design prioritizes social touch, particularly through fabric, to create a more human-like experience. Insights from our tactile sensing research will inform the gripper’s design, ensuring it can provide affective, controlled touch in applications such as therapy, caregiving, and companionship.</p>
                    </div>
                </div>
                <div class="col mb-4" data-aos="fade-right" data-aos-once="true"><a href="#"><img class="rounded img-fluid shadow w-100 fit-cover" src="assets/img/research-projects/ControlledGIF.gif" style="height: 350px;"></a>
                    <div class="py-4">
                        <h4 class="fw-bold text-center"><span style="font-weight: normal !important;">TurtleBots: Swarm</span></h4>
                        <p class="text-muted"><span style="color: rgb(51, 51, 51);">This project explores the interaction between humans and a group of mobile robots in a guided navigation context. Using TurtleBots upgraded with Raspberry Pis and running on ROS Noetic, we investigate how various aspects of multi-robot systems influence human reception and behavior. Specifically, we consider factors such as the number of robots involved, their spacing, proxemic distance, and the influence of auditory cues on the human experience. Our goal is to understand better how different configurations of robot behavior and environmental factors can optimize group interactions, enhance human comfort, and improve the effectiveness of robot-guided navigation in shared spaces.</span></p>
                    </div>
                </div>
                <div class="col mb-4" data-aos="fade-right" data-aos-once="true"><a href="#"><img class="rounded img-fluid shadow w-100 fit-cover" src="assets/img/research-projects/ControllerGIF.gif" style="height: 350px;"></a>
                    <div class="py-4">
                        <h4 class="fw-bold text-center"><span style="font-weight: normal !important;">TurtleBots: Charging Station</span></h4>
                        <p class="text-muted"><span style="color: rgb(51, 51, 51);">This project focuses on developing an autonomous, wireless charging solution for TurtleBots, ensuring continuous operation without human intervention. We are designing a custom wireless charging station for the TurtleBots. Then, using ROS Noetic and Raspberry Pi integration, we are implementing a system that enables the TurtleBot to detect when its battery is low and autonomously navigate to the charging station. This involves sensor-based localization, path planning, and efficient docking mechanisms to optimize reliability. The results of this project aim to replace wired solutions with cost-effective wireless and scalable charging stations for TurtleBots.</span></p>
                    </div>
                </div>
                <div class="col mb-4" data-aos="fade-left" data-aos-once="true"><a href="#"><img class="rounded img-fluid shadow w-100 fit-cover" src="assets/img/research-projects/phone.webp" style="height: 350px;"></a>
                    <div class="py-4">
                        <h4 class="fw-bold text-center"><span style="font-weight: normal !important;">Unplug Companion</span></h4>
                        <p class="text-muted">With society spending increasing time on mobile technology every year, large populations are negatively affected by excessive use.<br><br>The Unplug Companion project explores effective ways to improve the existing relationship between adults and mobile technology—using the smartphone itself. It investigates the&nbsp;impact of cognitive behavioral therapy (CBT), mindfulness-based journaling, peer support, and reflective literature on reducing screen time and improving one's well-being. By leveraging technology and behavioral science, our focus on human-computer interaction aims to draw conclusions that promote more intentional and meaningful technology uses for society.</p>
                    </div>
                </div>
            </div>
        </div><!-- End: Projects Grid -->
    </section><!-- Start: Footer Multi Column -->
    <footer class="bg-primary-gradient">
        <div class="container py-3">
            <div class="text-muted d-flex justify-content-between align-items-center pt-3">
                <p class="mb-0">Copyright © 2025 SaPHaRI Lab at Case Western Reserve University</p>
            </div>
        </div>
    </footer><!-- End: Footer Multi Column -->
    <script src="assets/bootstrap/js/bootstrap.min.js"></script>
    <script src="assets/js/aos.min.js"></script>
    <script src="assets/js/bs-init.js"></script>
    <script src="assets/js/bold-and-bright.js"></script>
</body>

</html>